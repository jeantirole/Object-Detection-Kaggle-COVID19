{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Ref\n## Data input \nhttps://www.kaggle.com/piantic/train-siim-covid-19-detection-fasterrcnn\n\n## EfficientDet\nhttps://www.kaggle.com/shonenkov/training-efficientdet","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:12.195526Z","iopub.execute_input":"2021-06-15T06:06:12.195908Z","iopub.status.idle":"2021-06-15T06:06:12.2005Z","shell.execute_reply.started":"2021-06-15T06:06:12.195879Z","shell.execute_reply":"2021-06-15T06:06:12.199062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Dependencies and imports","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null\n!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:12.369508Z","iopub.execute_input":"2021-06-15T06:06:12.369861Z","iopub.status.idle":"2021-06-15T06:06:16.905991Z","shell.execute_reply.started":"2021-06-15T06:06:12.369817Z","shell.execute_reply":"2021-06-15T06:06:16.904603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\nsys.path.insert(0, \"../input/omegaconf\")\n\nimport torch\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom glob import glob\n\nSEED = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:16.909137Z","iopub.execute_input":"2021-06-15T06:06:16.909606Z","iopub.status.idle":"2021-06-15T06:06:16.924117Z","shell.execute_reply.started":"2021-06-15T06:06:16.909565Z","shell.execute_reply":"2021-06-15T06:06:16.922812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Data Loader","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:16.927294Z","iopub.execute_input":"2021-06-15T06:06:16.928126Z","iopub.status.idle":"2021-06-15T06:06:16.937308Z","shell.execute_reply.started":"2021-06-15T06:06:16.928058Z","shell.execute_reply":"2021-06-15T06:06:16.936293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    return \"../input/siim-covid19-resized-to-256px-jpg/train/{}.jpg\".format(image_id)\n\ndef get_test_file_path(image_id):\n    return \"../input/siim-covid19-resized-to-256px-jpg/test/{}.jpg\".format(image_id)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:16.93971Z","iopub.execute_input":"2021-06-15T06:06:16.940202Z","iopub.status.idle":"2021-06-15T06:06:16.949841Z","shell.execute_reply.started":"2021-06-15T06:06:16.940159Z","shell.execute_reply":"2021-06-15T06:06:16.948805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nupdated_train_labels = pd.read_csv('../input/siim-covid19-updated-train-labels/updated_train_labels.csv')\n\nupdated_train_labels['jpg_path'] = updated_train_labels['id'].apply(get_train_file_path)\ntrain = updated_train_labels.copy()\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:16.951293Z","iopub.execute_input":"2021-06-15T06:06:16.952091Z","iopub.status.idle":"2021-06-15T06:06:17.058679Z","shell.execute_reply.started":"2021-06-15T06:06:16.952047Z","shell.execute_reply":"2021-06-15T06:06:17.057623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DefaultConfig:\n    n_folds: int = 5\n    seed: int = 2021\n    num_classes: int = 4 # \"negative\", \"typical\", \"indeterminate\", \"atypical\"\n    img_size: int = 256\n    fold_num: int = 0\n    device: str = 'cuda:0'","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:17.060348Z","iopub.execute_input":"2021-06-15T06:06:17.060784Z","iopub.status.idle":"2021-06-15T06:06:17.066538Z","shell.execute_reply.started":"2021-06-15T06:06:17.060727Z","shell.execute_reply":"2021-06-15T06:06:17.065268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_folds = train.copy()\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=DefaultConfig.seed)\nfor n, (train_index, val_index) in enumerate(skf.split(X=df_folds.index, y=df_folds.integer_label)):\n    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = int(n)\ndf_folds['fold'] = df_folds['fold'].astype(int)\nprint(df_folds.groupby(['fold', df_folds.integer_label]).size())","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:17.068554Z","iopub.execute_input":"2021-06-15T06:06:17.069085Z","iopub.status.idle":"2021-06-15T06:06:17.103956Z","shell.execute_reply.started":"2021-06-15T06:06:17.069041Z","shell.execute_reply":"2021-06-15T06:06:17.102691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Albumentation ","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:17.10654Z","iopub.execute_input":"2021-06-15T06:06:17.106983Z","iopub.status.idle":"2021-06-15T06:06:17.112839Z","shell.execute_reply.started":"2021-06-15T06:06:17.106943Z","shell.execute_reply":"2021-06-15T06:06:17.111184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose([\n        A.HorizontalFlip(p=0.5), \n        A.VerticalFlip(p=0.5),\n        A.OneOf([\n            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2,\n                                 val_shift_limit=0.2, p=0.3), \n            A.RandomBrightnessContrast(brightness_limit=0.2,  \n                                       contrast_limit=0.2, p=0.3),\n        ], p=0.2),\n        A.Resize(height=DefaultConfig.img_size, width=DefaultConfig.img_size, p=1.0),\n        #A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0),\n    ],\n    p=1.0, bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n\ndef get_valid_transforms():\n    return A.Compose([\n        A.Resize(height=DefaultConfig.img_size, width=DefaultConfig.img_size, p=1.0),\n        #A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0)\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:17.11543Z","iopub.execute_input":"2021-06-15T06:06:17.115997Z","iopub.status.idle":"2021-06-15T06:06:17.12701Z","shell.execute_reply.started":"2021-06-15T06:06:17.115922Z","shell.execute_reply":"2021-06-15T06:06:17.125602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Dataset & Dataloader","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:17.128935Z","iopub.execute_input":"2021-06-15T06:06:17.129413Z","iopub.status.idle":"2021-06-15T06:06:17.142177Z","shell.execute_reply.started":"2021-06-15T06:06:17.129357Z","shell.execute_reply":"2021-06-15T06:06:17.141054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(self, image_ids, df, transforms=None, test=False):\n        super().__init__()\n\n        self.image_ids = image_ids\n        self.df = df\n        self.file_names = df['jpg_path'].values\n        self.transforms = transforms\n        self.test = test\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        \n        image, boxes, labels = self.load_image_and_boxes(index)\n        \n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = torch.tensor(labels)\n        target['image_id'] = torch.tensor([index])\n\n        if self.transforms:\n            for i in range(10):\n                sample = self.transforms(**{\n                    'image': image,\n                    'bboxes': target['boxes'],\n                    'labels': labels\n                })\n                if len(sample['bboxes']) > 0:\n                    image = sample['image']\n                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n                    break\n        return image, target, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def load_image_and_boxes(self, index):\n        image_id = self.image_ids[index]\n        image = cv2.imread(self.file_names[index], cv2.IMREAD_COLOR).copy().astype(np.float32)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        records = self.df[self.df['id'] == image_id]       \n        boxes = []\n        for bbox in records[['frac_xmin', 'frac_ymin', 'frac_xmax', 'frac_ymax']].values:\n            bbox = np.clip(bbox, 0, 1.0)\n            temp = A.convert_bbox_from_albumentations(bbox, 'pascal_voc', image.shape[0], image.shape[0]) \n            boxes.append(temp)\n        '''\n        [0: 'atypical', 1: 'indeterminate', 2: 'negative', 3: 'typical']\n        '''\n        labels = records['integer_label'].values\n        return image, boxes, labels","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:17.519581Z","iopub.execute_input":"2021-06-15T06:06:17.519881Z","iopub.status.idle":"2021-06-15T06:06:17.533238Z","shell.execute_reply.started":"2021-06-15T06:06:17.519853Z","shell.execute_reply":"2021-06-15T06:06:17.531671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_folds = df_folds.set_index('id')\n\ndef get_train_dataset(fold_number):    \n    return CustomDataset(\n        image_ids = df_folds[df_folds['fold'] != fold_number].index.values,\n        df = train,\n        transforms = get_train_transforms()\n    )\n\ndef get_validation_dataset(fold_number):\n    return CustomDataset(\n        image_ids = df_folds[df_folds['fold'] == fold_number].index.values,\n        df = train,\n        transforms = get_valid_transforms()\n    )\n\ndef get_train_data_loader(train_dataset, batch_size=16):\n    return DataLoader(\n        train_dataset,\n        batch_size = batch_size,\n        shuffle = False,\n        num_workers = 4,\n        collate_fn = collate_fn\n    )\n\ndef get_validation_data_loader(valid_dataset, batch_size=16):\n    return DataLoader(\n        valid_dataset,\n        batch_size = batch_size,\n        shuffle = False,\n        num_workers = 4,\n        collate_fn = collate_fn\n    )    \n\ndef collate_fn(batch):\n    return tuple(zip(*batch))","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:18.78022Z","iopub.execute_input":"2021-06-15T06:06:18.780588Z","iopub.status.idle":"2021-06-15T06:06:18.793599Z","shell.execute_reply.started":"2021-06-15T06:06:18.78056Z","shell.execute_reply":"2021-06-15T06:06:18.792278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show One Image using Dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:06:19.624944Z","iopub.execute_input":"2021-06-15T06:06:19.625291Z","iopub.status.idle":"2021-06-15T06:06:19.632485Z","shell.execute_reply.started":"2021-06-15T06:06:19.625261Z","shell.execute_reply":"2021-06-15T06:06:19.630993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold= 0 \ntrain_dataset = get_train_dataset(fold_number=fold)\ntrain_data_loader = get_train_data_loader(\n    train_dataset,\n    batch_size=TrainGlobalConfig.batch_size\n)\n\nvalidation_dataset = get_validation_dataset(fold_number=fold)\nvalidation_data_loader = get_validation_data_loader(\n    validation_dataset, \n    batch_size=TrainGlobalConfig.batch_size\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:09:37.873975Z","iopub.execute_input":"2021-06-15T06:09:37.874388Z","iopub.status.idle":"2021-06-15T06:09:37.890744Z","shell.execute_reply.started":"2021-06-15T06:09:37.874356Z","shell.execute_reply":"2021-06-15T06:09:37.889255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, target, image_id = train_dataset[2]\nboxes = target['boxes'].cpu().numpy().astype(np.int32)\n\nnumpy_image = image.permute(1,2,0).cpu().numpy()\n\nfig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(numpy_image, (box[0], box[1]), (box[2],  box[3]), (0, 255, 0), 2)\n    \nax.set_axis_off()\nax.imshow(numpy_image);","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:09:52.362713Z","iopub.execute_input":"2021-06-15T06:09:52.363073Z","iopub.status.idle":"2021-06-15T06:09:52.529613Z","shell.execute_reply.started":"2021-06-15T06:09:52.363044Z","shell.execute_reply":"2021-06-15T06:09:52.528559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:09:57.582703Z","iopub.execute_input":"2021-06-15T06:09:57.583073Z","iopub.status.idle":"2021-06-15T06:09:57.593914Z","shell.execute_reply.started":"2021-06-15T06:09:57.583043Z","shell.execute_reply":"2021-06-15T06:09:57.591426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Fitter","metadata":{"execution":{"iopub.status.busy":"2021-06-15T05:49:02.141895Z","iopub.execute_input":"2021-06-15T05:49:02.142301Z","iopub.status.idle":"2021-06-15T05:49:02.147589Z","shell.execute_reply.started":"2021-06-15T05:49:02.142254Z","shell.execute_reply":"2021-06-15T05:49:02.146184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:11:25.178864Z","iopub.execute_input":"2021-06-15T06:11:25.179205Z","iopub.status.idle":"2021-06-15T06:11:25.186855Z","shell.execute_reply.started":"2021-06-15T06:11:25.179174Z","shell.execute_reply":"2021-06-15T06:11:25.185211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nclass Fitter:\n    \n    def __init__(self, model, device, config):\n        self.config = config\n        self.epoch = 0\n\n        self.base_dir = f'./{config.folder}'\n        if not os.path.exists(self.base_dir):\n            os.makedirs(self.base_dir)\n        \n        self.log_path = f'{self.base_dir}/log.txt'\n        self.best_summary_loss = 10**5\n\n        self.model = model\n        self.device = device\n\n        param_optimizer = list(self.model.named_parameters())\n        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ] \n\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, validation_loader):\n        for e in range(self.config.n_epochs):\n            if self.config.verbose:\n                lr = self.optimizer.param_groups[0]['lr']\n                timestamp = datetime.utcnow().isoformat()\n                self.log(f'\\n{timestamp}\\nLR: {lr}')\n\n            t = time.time()\n            summary_loss = self.train_one_epoch(train_loader)\n\n            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n            self.save(f'{self.base_dir}/last-checkpoint.bin')\n\n            t = time.time()\n            summary_loss = self.validation(validation_loader)\n\n            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n            if summary_loss.avg < self.best_summary_loss:\n                self.best_summary_loss = summary_loss.avg\n                self.model.eval()\n                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n                    os.remove(path)\n\n            if self.config.validation_scheduler:\n                self.scheduler.step(metrics=summary_loss.avg)\n\n            self.epoch += 1\n\n    def validation(self, val_loader):\n        self.model.eval()\n        summary_loss = AverageMeter()\n        t = time.time()\n        for step, (images, targets, image_ids) in enumerate(val_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Val Step {step}/{len(val_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            with torch.no_grad():\n                images = torch.stack(images)\n                batch_size = images.shape[0]\n                images = images.to(self.device).float()\n                boxes = [target['boxes'].to(self.device).float() for target in targets]\n                labels = [target['labels'].to(self.device).float() for target in targets]\n\n                loss, _, _ = self.model(images, boxes, labels)\n                summary_loss.update(loss.detach().item(), batch_size)\n\n        return summary_loss\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = AverageMeter()\n        t = time.time()\n        for step, (images, targets, image_ids) in enumerate(train_loader):\n            if self.config.verbose:\n                if step % self.config.verbose_step == 0:\n                    print(\n                        f'Train Step {step}/{len(train_loader)}, ' + \\\n                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                        f'time: {(time.time() - t):.5f}', end='\\r'\n                    )\n            \n            images = torch.stack(images)\n            images = images.to(self.device).float()\n            batch_size = images.shape[0]\n            boxes = [target['boxes'].to(self.device).float() for target in targets]\n            labels = [target['labels'].to(self.device).float() for target in targets]\n\n            self.optimizer.zero_grad()\n            \n            loss, _, _ = self.model(images, boxes, labels)\n            \n            loss.backward()\n\n            summary_loss.update(loss.detach().item(), batch_size)\n\n            self.optimizer.step()\n\n            if self.config.step_scheduler:\n                self.scheduler.step()\n\n        return summary_loss\n    \n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_summary_loss': self.best_summary_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_summary_loss = checkpoint['best_summary_loss']\n        self.epoch = checkpoint['epoch'] + 1\n        \n    def log(self, message):\n        if self.config.verbose:\n            print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-15T05:49:02.163467Z","iopub.execute_input":"2021-06-15T05:49:02.16404Z","iopub.status.idle":"2021-06-15T05:49:02.200475Z","shell.execute_reply.started":"2021-06-15T05:49:02.163994Z","shell.execute_reply":"2021-06-15T05:49:02.199317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainGlobalConfig:\n    num_workers = 2\n    batch_size = 4 \n    n_epochs = 3 # n_epochs = 40\n    lr = 0.0002\n\n    folder = 'effdet5-cutmix-augmix'\n\n    # -------------------\n    verbose = True\n    verbose_step = 1\n    # -------------------\n\n    # --------------------\n    step_scheduler = False  # do scheduler.step after optimizer.step\n    validation_scheduler = True  # do scheduler.step after validation stage loss\n\n#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n#     scheduler_params = dict(\n#         max_lr=0.001,\n#         epochs=n_epochs,\n#         steps_per_epoch=int(len(train_dataset) / batch_size),\n#         pct_start=0.1,\n#         anneal_strategy='cos', \n#         final_div_factor=10**5\n#     )\n    \n    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode='min',\n        factor=0.5,\n        patience=1,\n        verbose=False, \n        threshold=0.0001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-8,\n        eps=1e-08\n    )\n    # --------------------","metadata":{"execution":{"iopub.status.busy":"2021-06-15T05:49:02.202371Z","iopub.execute_input":"2021-06-15T05:49:02.203309Z","iopub.status.idle":"2021-06-15T05:49:02.214039Z","shell.execute_reply.started":"2021-06-15T05:49:02.203256Z","shell.execute_reply":"2021-06-15T05:49:02.212957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ndef run_training(fold=0):\n    net.to(device)\n    \n    train_dataset = get_train_dataset(fold_number=fold)\n    train_data_loader = get_train_data_loader(\n        train_dataset,\n        batch_size=TrainGlobalConfig.batch_size\n    )\n    \n    validation_dataset = get_validation_dataset(fold_number=fold)\n    validation_data_loader = get_validation_data_loader(\n        validation_dataset, \n        batch_size=TrainGlobalConfig.batch_size\n    )\n\n    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n    fitter.fit(train_data_loader, validation_data_loader)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:20:53.700246Z","iopub.execute_input":"2021-06-15T06:20:53.700769Z","iopub.status.idle":"2021-06-15T06:20:53.714269Z","shell.execute_reply.started":"2021-06-15T06:20:53.700707Z","shell.execute_reply":"2021-06-15T06:20:53.712743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\nfrom effdet.efficientdet import HeadNet\n\ndef get_net():\n    config = get_efficientdet_config('tf_efficientdet_d5')\n    net = EfficientDet(config, pretrained_backbone=False)\n    checkpoint = torch.load('../input/efficientdet/efficientdet_d5-ef44aea8.pth')\n    net.load_state_dict(checkpoint)\n    config.num_classes = 4\n    config.image_size = 256\n    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n    return DetBenchTrain(net, config)\n\nnet = get_net()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:21:34.514352Z","iopub.execute_input":"2021-06-15T06:21:34.514695Z","iopub.status.idle":"2021-06-15T06:21:36.025761Z","shell.execute_reply.started":"2021-06-15T06:21:34.514662Z","shell.execute_reply":"2021-06-15T06:21:36.024742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_training()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T06:21:36.027372Z","iopub.execute_input":"2021-06-15T06:21:36.027803Z","iopub.status.idle":"2021-06-15T07:39:56.078876Z","shell.execute_reply.started":"2021-06-15T06:21:36.027773Z","shell.execute_reply":"2021-06-15T07:39:56.075202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}